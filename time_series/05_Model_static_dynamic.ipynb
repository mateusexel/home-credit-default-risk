{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dependent-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, LSTM, Bidirectional, Dropout, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strange-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateus/anaconda3/envs/home-credit/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df_static = pd.read_csv('../treated_data/df_static.csv',index_col=0)\n",
    "df_dynamic = pd.read_csv('../treated_data/df_dynamic.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "common-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(df_static.index ,df_static.TARGET, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fatty-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_static_train = df_static.loc[X_train]\n",
    "X_static_train = X_static_train.fillna(X_static_train.mean()).values[:,1:]\n",
    "\n",
    "X_static_test = df_static.loc[X_test]\n",
    "X_static_test = X_static_test.fillna(X_static_train.mean()).values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vocal-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dynamic_train = df_dynamic.loc[X_train].reset_index()\n",
    "X_dynamic_train = X_dynamic_train.fillna(X_dynamic_train.mean())\n",
    "X_dynamic_train = X_dynamic_train.pivot_table(values=list(set(X_dynamic_train.columns)-set(['SK_ID_PREV', 'MONTHS_BALANCE','SK_ID_CURR'])), index='SK_ID_CURR', columns='MONTHS_BALANCE',aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mediterranean-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dynamic_train = df_dynamic.loc[X_train].reset_index()\n",
    "X_dynamic_train = X_dynamic_train.fillna(X_dynamic_train.mean())\n",
    "X_dynamic_train = X_dynamic_train.pivot_table(values=list(set(X_dynamic_train.columns)-set(['SK_ID_PREV', 'MONTHS_BALANCE','SK_ID_CURR'])), index='SK_ID_CURR', columns='MONTHS_BALANCE',aggfunc='sum', fill_value=0).values\n",
    "\n",
    "\n",
    "X_dynamic_test = df_dynamic.loc[X_test].reset_index()\n",
    "X_dynamic_test = X_dynamic_test.fillna(X_dynamic_train.mean())\n",
    "X_dynamic_test = X_dynamic_test.pivot_table(values=list(set(X_dynamic_test.columns)-set(['SK_ID_PREV', 'MONTHS_BALANCE','SK_ID_CURR'])), index='SK_ID_CURR', columns='MONTHS_BALANCE', aggfunc='sum', fill_value=0).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reserved-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dynamic_train_reshaped = np.zeros((33265, 97,57))\n",
    "\n",
    "for l in range(33265):\n",
    "    for o in range(97):\n",
    "        for i in range(57):\n",
    "            X_dynamic_train_reshaped[l,o,i]=X_dynamic_train[l,i*97+o]\n",
    "\n",
    "            \n",
    "X_dynamic_test_reshaped = np.zeros((16385, 97,57))\n",
    "\n",
    "for l in range(16385):\n",
    "    for o in range(97):\n",
    "        for i in range(57):\n",
    "            X_dynamic_test_reshaped[l,o,i]=X_dynamic_test[l,i*97+o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "empty-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_static_train = scaler.fit_transform(X_static_train)\n",
    "X_static_test = scaler.transform(X_static_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annoying-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for i in range(X_dynamic_train_reshaped.shape[2]):\n",
    "    scalers[i] = MinMaxScaler()\n",
    "    X_dynamic_train_reshaped[:, :, i] = scalers[i].fit_transform(X_dynamic_train_reshaped[:, :, i]) \n",
    "\n",
    "for i in range(X_dynamic_test_reshaped.shape[2]):\n",
    "    X_dynamic_test_reshaped[:, :, 1] = scalers[i].transform(X_dynamic_test_reshaped[:, :, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-shoot",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x_in_dy = Input(shape=(97,22))\n",
    "# x_in_st = Input(shape=(200))\n",
    "\n",
    "# x_dy = Bidirectional(LSTM(84, return_sequences=True))(x_in_dy)\n",
    "# x_dy = Dropout(0.6)(x_dy)\n",
    "# x_dy = Bidirectional(LSTM(46))(x_dy)\n",
    "\n",
    "# x_st = Dense(100, activation=\"relu\")(x_in_st)\n",
    "# x_st = Dropout(0.6)(x_st)\n",
    "# x_st = Dense(50, activation=\"relu\")(x_st)\n",
    "\n",
    "\n",
    "\n",
    "# z=concatenate([x_dy,x_st])\n",
    "\n",
    "# out = Dense(24, activation='relu')(z)\n",
    "# out = Dropout(0.5)(out)\n",
    "# out = Dense(1, activation='sigmoid')(out)\n",
    "# model1 = Model(inputs = [x_in_dy,x_in_st], outputs = out)\n",
    "\n",
    "\n",
    "x_in_dy = Input(shape=(36,57))\n",
    "\n",
    "x_dy = Bidirectional(LSTM(80, return_sequences=True))(x_in_dy)\n",
    "x_dy = Dropout(0.5)(x_dy)\n",
    "x_dy = Bidirectional(LSTM(80))(x_in_dy)\n",
    "\n",
    "out = Dense(50, activation='relu')(x_dy)\n",
    "# out = Dropout(0.5)(out)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "model1 = Model(inputs = x_in_dy, outputs = out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "raising-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.compile(optimizer='rmsprop', \n",
    "#               loss = 'binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# history = model1.fit([X_dynamic_train, X_static_train], y_train, epochs=100, batch_size= 1000, validation_data=([X_dynamic_test, X_static_test], y_test)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expressed-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(lr=0.05)\n",
    "m = tf.keras.metrics.AUC(num_thresholds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "another-peripheral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "80/80 [==============================] - 4s 53ms/step - loss: 0.6936 - accuracy: 0.5050 - val_loss: 0.7023 - val_accuracy: 0.4966\n",
      "Epoch 2/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6927 - accuracy: 0.5105 - val_loss: 0.7012 - val_accuracy: 0.5046\n",
      "Epoch 3/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6921 - accuracy: 0.5138 - val_loss: 0.7095 - val_accuracy: 0.5101\n",
      "Epoch 4/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6917 - accuracy: 0.5131 - val_loss: 0.7365 - val_accuracy: 0.5145\n",
      "Epoch 5/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6912 - accuracy: 0.5134 - val_loss: 0.7562 - val_accuracy: 0.5014\n",
      "Epoch 6/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6900 - accuracy: 0.5197 - val_loss: 0.7591 - val_accuracy: 0.5016\n",
      "Epoch 7/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6893 - accuracy: 0.5264 - val_loss: 0.8331 - val_accuracy: 0.5030\n",
      "Epoch 8/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6898 - accuracy: 0.5226 - val_loss: 0.8057 - val_accuracy: 0.5021\n",
      "Epoch 9/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6887 - accuracy: 0.5301 - val_loss: 0.8630 - val_accuracy: 0.4988\n",
      "Epoch 10/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6882 - accuracy: 0.5285 - val_loss: 0.9125 - val_accuracy: 0.5011\n",
      "Epoch 11/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6875 - accuracy: 0.5307 - val_loss: 0.9278 - val_accuracy: 0.4989\n",
      "Epoch 12/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6872 - accuracy: 0.5320 - val_loss: 1.0333 - val_accuracy: 0.4984\n",
      "Epoch 13/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6876 - accuracy: 0.5284 - val_loss: 1.1184 - val_accuracy: 0.4984\n",
      "Epoch 14/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6858 - accuracy: 0.5401 - val_loss: 1.2234 - val_accuracy: 0.4985\n",
      "Epoch 15/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6856 - accuracy: 0.5356 - val_loss: 1.2381 - val_accuracy: 0.5004\n",
      "Epoch 16/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6857 - accuracy: 0.5342 - val_loss: 1.3155 - val_accuracy: 0.4994\n",
      "Epoch 17/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6839 - accuracy: 0.5431 - val_loss: 1.4944 - val_accuracy: 0.5022\n",
      "Epoch 18/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6841 - accuracy: 0.5423 - val_loss: 1.6431 - val_accuracy: 0.5045\n",
      "Epoch 19/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6830 - accuracy: 0.5414 - val_loss: 1.4479 - val_accuracy: 0.5096\n",
      "Epoch 20/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6826 - accuracy: 0.5442 - val_loss: 1.4531 - val_accuracy: 0.5078\n",
      "Epoch 21/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6825 - accuracy: 0.5467 - val_loss: 1.4079 - val_accuracy: 0.5095\n",
      "Epoch 22/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6816 - accuracy: 0.5468 - val_loss: 1.4231 - val_accuracy: 0.5094\n",
      "Epoch 23/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6825 - accuracy: 0.5415 - val_loss: 1.4469 - val_accuracy: 0.5093\n",
      "Epoch 24/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6807 - accuracy: 0.5488 - val_loss: 1.5875 - val_accuracy: 0.5114\n",
      "Epoch 25/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6796 - accuracy: 0.5521 - val_loss: 1.7353 - val_accuracy: 0.5102\n",
      "Epoch 26/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6791 - accuracy: 0.5499 - val_loss: 1.6638 - val_accuracy: 0.5110\n",
      "Epoch 27/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6793 - accuracy: 0.5511 - val_loss: 1.6264 - val_accuracy: 0.5076\n",
      "Epoch 28/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6781 - accuracy: 0.5503 - val_loss: 1.7060 - val_accuracy: 0.4971\n",
      "Epoch 29/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6771 - accuracy: 0.5545 - val_loss: 1.7453 - val_accuracy: 0.4982\n",
      "Epoch 30/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6782 - accuracy: 0.5515 - val_loss: 1.6509 - val_accuracy: 0.4973\n",
      "Epoch 31/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6768 - accuracy: 0.5530 - val_loss: 1.7872 - val_accuracy: 0.4945\n",
      "Epoch 32/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6759 - accuracy: 0.5543 - val_loss: 1.7436 - val_accuracy: 0.4884\n",
      "Epoch 33/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6765 - accuracy: 0.5502 - val_loss: 1.8240 - val_accuracy: 0.4922\n",
      "Epoch 34/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6749 - accuracy: 0.5554 - val_loss: 1.9355 - val_accuracy: 0.4934\n",
      "Epoch 35/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6745 - accuracy: 0.5555 - val_loss: 1.9474 - val_accuracy: 0.4917\n",
      "Epoch 36/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6738 - accuracy: 0.5572 - val_loss: 2.1945 - val_accuracy: 0.4903\n",
      "Epoch 37/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6729 - accuracy: 0.5614 - val_loss: 2.1963 - val_accuracy: 0.4893\n",
      "Epoch 38/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6722 - accuracy: 0.5609 - val_loss: 2.1866 - val_accuracy: 0.4894\n",
      "Epoch 39/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6713 - accuracy: 0.5603 - val_loss: 2.2829 - val_accuracy: 0.4890\n",
      "Epoch 40/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6708 - accuracy: 0.5587 - val_loss: 2.2597 - val_accuracy: 0.4926\n",
      "Epoch 41/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6715 - accuracy: 0.5555 - val_loss: 2.1545 - val_accuracy: 0.4926\n",
      "Epoch 42/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6718 - accuracy: 0.5596 - val_loss: 2.2355 - val_accuracy: 0.5019\n",
      "Epoch 43/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6695 - accuracy: 0.5632 - val_loss: 2.3009 - val_accuracy: 0.5022\n",
      "Epoch 44/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6676 - accuracy: 0.5684 - val_loss: 2.3915 - val_accuracy: 0.5004\n",
      "Epoch 45/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6667 - accuracy: 0.5687 - val_loss: 2.3998 - val_accuracy: 0.4980\n",
      "Epoch 46/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6664 - accuracy: 0.5650 - val_loss: 2.5028 - val_accuracy: 0.4964\n",
      "Epoch 47/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6682 - accuracy: 0.5672 - val_loss: 2.5746 - val_accuracy: 0.4984\n",
      "Epoch 48/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6672 - accuracy: 0.5671 - val_loss: 2.5092 - val_accuracy: 0.4966\n",
      "Epoch 49/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6662 - accuracy: 0.5629 - val_loss: 2.6307 - val_accuracy: 0.4981\n",
      "Epoch 50/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6634 - accuracy: 0.5699 - val_loss: 2.8514 - val_accuracy: 0.5032\n",
      "Epoch 51/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6648 - accuracy: 0.5671 - val_loss: 2.8406 - val_accuracy: 0.4956\n",
      "Epoch 52/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6648 - accuracy: 0.5675 - val_loss: 2.5095 - val_accuracy: 0.5014\n",
      "Epoch 53/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6636 - accuracy: 0.5662 - val_loss: 2.7119 - val_accuracy: 0.5047\n",
      "Epoch 54/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6617 - accuracy: 0.5718 - val_loss: 3.2671 - val_accuracy: 0.4987\n",
      "Epoch 55/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6604 - accuracy: 0.5741 - val_loss: 3.2572 - val_accuracy: 0.4953\n",
      "Epoch 56/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6602 - accuracy: 0.5744 - val_loss: 3.0052 - val_accuracy: 0.4980\n",
      "Epoch 57/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6621 - accuracy: 0.5685 - val_loss: 3.2439 - val_accuracy: 0.4991\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6594 - accuracy: 0.5726 - val_loss: 3.3085 - val_accuracy: 0.4986\n",
      "Epoch 59/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6582 - accuracy: 0.5731 - val_loss: 3.5384 - val_accuracy: 0.4999\n",
      "Epoch 60/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6595 - accuracy: 0.5727 - val_loss: 3.5570 - val_accuracy: 0.4931\n",
      "Epoch 61/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6578 - accuracy: 0.5764 - val_loss: 3.7213 - val_accuracy: 0.4993\n",
      "Epoch 62/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6567 - accuracy: 0.5759 - val_loss: 3.6929 - val_accuracy: 0.4911\n",
      "Epoch 63/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6548 - accuracy: 0.5804 - val_loss: 4.1839 - val_accuracy: 0.4948\n",
      "Epoch 64/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6581 - accuracy: 0.5706 - val_loss: 3.8080 - val_accuracy: 0.4897\n",
      "Epoch 65/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6546 - accuracy: 0.5767 - val_loss: 3.9736 - val_accuracy: 0.4922\n",
      "Epoch 66/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6542 - accuracy: 0.5824 - val_loss: 3.9396 - val_accuracy: 0.4923\n",
      "Epoch 67/300\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.6556 - accuracy: 0.5760 - val_loss: 3.9046 - val_accuracy: 0.4942\n",
      "Epoch 68/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6554 - accuracy: 0.5817 - val_loss: 3.9804 - val_accuracy: 0.4914\n",
      "Epoch 69/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6564 - accuracy: 0.5769 - val_loss: 4.1691 - val_accuracy: 0.4896\n",
      "Epoch 70/300\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.6544 - accuracy: 0.5759 - val_loss: 4.2869 - val_accuracy: 0.4915\n",
      "Epoch 71/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6518 - accuracy: 0.5813 - val_loss: 4.5271 - val_accuracy: 0.4934\n",
      "Epoch 72/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6507 - accuracy: 0.5833 - val_loss: 4.2841 - val_accuracy: 0.4947\n",
      "Epoch 73/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6504 - accuracy: 0.5831 - val_loss: 4.4333 - val_accuracy: 0.4933\n",
      "Epoch 74/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6490 - accuracy: 0.5819 - val_loss: 4.9316 - val_accuracy: 0.4967\n",
      "Epoch 75/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6504 - accuracy: 0.5790 - val_loss: 4.8369 - val_accuracy: 0.4943\n",
      "Epoch 76/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6512 - accuracy: 0.5855 - val_loss: 4.7642 - val_accuracy: 0.4903\n",
      "Epoch 77/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6502 - accuracy: 0.5853 - val_loss: 5.1338 - val_accuracy: 0.4975\n",
      "Epoch 78/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6480 - accuracy: 0.5851 - val_loss: 5.5878 - val_accuracy: 0.4950\n",
      "Epoch 79/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6516 - accuracy: 0.5815 - val_loss: 4.8381 - val_accuracy: 0.4964\n",
      "Epoch 80/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6503 - accuracy: 0.5796 - val_loss: 4.8872 - val_accuracy: 0.4965\n",
      "Epoch 81/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6459 - accuracy: 0.5900 - val_loss: 4.9805 - val_accuracy: 0.4981\n",
      "Epoch 82/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6461 - accuracy: 0.5854 - val_loss: 5.3780 - val_accuracy: 0.4982\n",
      "Epoch 83/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6445 - accuracy: 0.5896 - val_loss: 5.3860 - val_accuracy: 0.4991\n",
      "Epoch 84/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6442 - accuracy: 0.5906 - val_loss: 5.7248 - val_accuracy: 0.4981\n",
      "Epoch 85/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6444 - accuracy: 0.5863 - val_loss: 5.6971 - val_accuracy: 0.4939\n",
      "Epoch 86/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6446 - accuracy: 0.5893 - val_loss: 5.7370 - val_accuracy: 0.4948\n",
      "Epoch 87/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6460 - accuracy: 0.5887 - val_loss: 5.1539 - val_accuracy: 0.4981\n",
      "Epoch 88/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6453 - accuracy: 0.5886 - val_loss: 5.2357 - val_accuracy: 0.4964\n",
      "Epoch 89/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6421 - accuracy: 0.5913 - val_loss: 5.5114 - val_accuracy: 0.4975\n",
      "Epoch 90/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6422 - accuracy: 0.5895 - val_loss: 5.0922 - val_accuracy: 0.4962\n",
      "Epoch 91/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6428 - accuracy: 0.5897 - val_loss: 5.1655 - val_accuracy: 0.4966\n",
      "Epoch 92/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6401 - accuracy: 0.5902 - val_loss: 5.1295 - val_accuracy: 0.4934\n",
      "Epoch 93/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6395 - accuracy: 0.5931 - val_loss: 5.3025 - val_accuracy: 0.4934\n",
      "Epoch 94/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6386 - accuracy: 0.5939 - val_loss: 5.5252 - val_accuracy: 0.4912\n",
      "Epoch 95/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6390 - accuracy: 0.5966 - val_loss: 5.5409 - val_accuracy: 0.4966\n",
      "Epoch 96/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6399 - accuracy: 0.5898 - val_loss: 5.5078 - val_accuracy: 0.4963\n",
      "Epoch 97/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6385 - accuracy: 0.5942 - val_loss: 6.1810 - val_accuracy: 0.4952\n",
      "Epoch 98/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6422 - accuracy: 0.5942 - val_loss: 5.4360 - val_accuracy: 0.4945\n",
      "Epoch 99/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6405 - accuracy: 0.5949 - val_loss: 5.8738 - val_accuracy: 0.4923\n",
      "Epoch 100/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6386 - accuracy: 0.5962 - val_loss: 5.3583 - val_accuracy: 0.4889\n",
      "Epoch 101/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6371 - accuracy: 0.5928 - val_loss: 5.4720 - val_accuracy: 0.4933\n",
      "Epoch 102/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6351 - accuracy: 0.5948 - val_loss: 6.0195 - val_accuracy: 0.4951\n",
      "Epoch 103/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.6347 - accuracy: 0.5969 - val_loss: 5.9959 - val_accuracy: 0.4906\n",
      "Epoch 104/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.6391 - accuracy: 0.5928 - val_loss: 6.8372 - val_accuracy: 0.4949\n",
      "Epoch 105/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6356 - accuracy: 0.5969 - val_loss: 6.8135 - val_accuracy: 0.4908\n",
      "Epoch 106/300\n",
      "80/80 [==============================] - 4s 51ms/step - loss: 0.6353 - accuracy: 0.5981 - val_loss: 7.3546 - val_accuracy: 0.4950\n",
      "Epoch 107/300\n",
      "80/80 [==============================] - 5s 56ms/step - loss: 0.6340 - accuracy: 0.6010 - val_loss: 6.5293 - val_accuracy: 0.4923\n",
      "Epoch 108/300\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.6335 - accuracy: 0.6001 - val_loss: 6.3335 - val_accuracy: 0.4939\n",
      "Epoch 109/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6335 - accuracy: 0.5965 - val_loss: 6.5688 - val_accuracy: 0.4921\n",
      "Epoch 110/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6321 - accuracy: 0.6036 - val_loss: 6.3052 - val_accuracy: 0.4923\n",
      "Epoch 111/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.6315 - accuracy: 0.5972 - val_loss: 6.0659 - val_accuracy: 0.4981\n",
      "Epoch 112/300\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.6308 - accuracy: 0.6020 - val_loss: 5.9788 - val_accuracy: 0.4930\n",
      "Epoch 113/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.6312 - accuracy: 0.6008 - val_loss: 6.2433 - val_accuracy: 0.4972\n",
      "Epoch 114/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.6339 - accuracy: 0.5958 - val_loss: 5.9628 - val_accuracy: 0.4937\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6356 - accuracy: 0.5969 - val_loss: 5.8983 - val_accuracy: 0.4876\n",
      "Epoch 116/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6335 - accuracy: 0.6009 - val_loss: 5.8885 - val_accuracy: 0.4865\n",
      "Epoch 117/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6346 - accuracy: 0.5958 - val_loss: 5.7847 - val_accuracy: 0.4875\n",
      "Epoch 118/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.6305 - accuracy: 0.6023 - val_loss: 6.1120 - val_accuracy: 0.4909\n",
      "Epoch 119/300\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6281 - accuracy: 0.6022 - val_loss: 6.3131 - val_accuracy: 0.4894\n",
      "Epoch 120/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6276 - accuracy: 0.6027 - val_loss: 6.2525 - val_accuracy: 0.4876\n",
      "Epoch 121/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.6270 - accuracy: 0.6026 - val_loss: 6.4527 - val_accuracy: 0.4865\n",
      "Epoch 122/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.6275 - accuracy: 0.6079 - val_loss: 6.5304 - val_accuracy: 0.4893\n",
      "Epoch 123/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.6286 - accuracy: 0.5965 - val_loss: 6.4477 - val_accuracy: 0.4886\n",
      "Epoch 124/300\n",
      "80/80 [==============================] - 5s 59ms/step - loss: 0.6269 - accuracy: 0.6044 - val_loss: 6.6965 - val_accuracy: 0.4863\n",
      "Epoch 125/300\n",
      "80/80 [==============================] - 4s 54ms/step - loss: 0.6269 - accuracy: 0.6047 - val_loss: 6.7989 - val_accuracy: 0.4901\n",
      "Epoch 126/300\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.6251 - accuracy: 0.6052 - val_loss: 6.8512 - val_accuracy: 0.4922\n",
      "Epoch 127/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6239 - accuracy: 0.6051 - val_loss: 6.7772 - val_accuracy: 0.4931\n",
      "Epoch 128/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6241 - accuracy: 0.6048 - val_loss: 6.7749 - val_accuracy: 0.4878\n",
      "Epoch 129/300\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.6219 - accuracy: 0.6054 - val_loss: 7.1041 - val_accuracy: 0.4905\n",
      "Epoch 130/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6238 - accuracy: 0.6090 - val_loss: 6.9481 - val_accuracy: 0.4877\n",
      "Epoch 131/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6294 - accuracy: 0.6024 - val_loss: 6.6295 - val_accuracy: 0.4867\n",
      "Epoch 132/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6334 - accuracy: 0.6004 - val_loss: 6.2889 - val_accuracy: 0.4829\n",
      "Epoch 133/300\n",
      "80/80 [==============================] - 6s 74ms/step - loss: 0.6267 - accuracy: 0.6053 - val_loss: 6.5775 - val_accuracy: 0.4856\n",
      "Epoch 134/300\n",
      "80/80 [==============================] - 4s 55ms/step - loss: 0.6228 - accuracy: 0.6045 - val_loss: 6.4798 - val_accuracy: 0.4861\n",
      "Epoch 135/300\n",
      "80/80 [==============================] - 4s 52ms/step - loss: 0.6193 - accuracy: 0.6084 - val_loss: 6.8371 - val_accuracy: 0.4847\n",
      "Epoch 136/300\n",
      "80/80 [==============================] - 4s 56ms/step - loss: 0.6197 - accuracy: 0.6087 - val_loss: 6.6137 - val_accuracy: 0.4876\n",
      "Epoch 137/300\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 0.6202 - accuracy: 0.6085 - val_loss: 6.8351 - val_accuracy: 0.4875\n",
      "Epoch 138/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6191 - accuracy: 0.6092 - val_loss: 7.3634 - val_accuracy: 0.4904\n",
      "Epoch 139/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6195 - accuracy: 0.6084 - val_loss: 7.2610 - val_accuracy: 0.4836\n",
      "Epoch 140/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6180 - accuracy: 0.6081 - val_loss: 7.1228 - val_accuracy: 0.4839\n",
      "Epoch 141/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6226 - accuracy: 0.6060 - val_loss: 7.4571 - val_accuracy: 0.4809\n",
      "Epoch 142/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6218 - accuracy: 0.6092 - val_loss: 6.6706 - val_accuracy: 0.4896\n",
      "Epoch 143/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6214 - accuracy: 0.6076 - val_loss: 6.9081 - val_accuracy: 0.4877\n",
      "Epoch 144/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6166 - accuracy: 0.6083 - val_loss: 7.6770 - val_accuracy: 0.4845\n",
      "Epoch 145/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6184 - accuracy: 0.6099 - val_loss: 7.4132 - val_accuracy: 0.4814\n",
      "Epoch 146/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6153 - accuracy: 0.6114 - val_loss: 7.5647 - val_accuracy: 0.4816\n",
      "Epoch 147/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6140 - accuracy: 0.6124 - val_loss: 7.8645 - val_accuracy: 0.4797\n",
      "Epoch 148/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6145 - accuracy: 0.6134 - val_loss: 7.8920 - val_accuracy: 0.4831\n",
      "Epoch 149/300\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.6143 - accuracy: 0.6170 - val_loss: 7.8563 - val_accuracy: 0.4854\n",
      "Epoch 150/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6152 - accuracy: 0.6103 - val_loss: 7.8204 - val_accuracy: 0.4896\n",
      "Epoch 151/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6122 - accuracy: 0.6143 - val_loss: 7.9126 - val_accuracy: 0.4872\n",
      "Epoch 152/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6159 - accuracy: 0.6115 - val_loss: 8.0323 - val_accuracy: 0.4861\n",
      "Epoch 153/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6223 - accuracy: 0.6089 - val_loss: 7.1299 - val_accuracy: 0.4919\n",
      "Epoch 154/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6212 - accuracy: 0.6066 - val_loss: 7.3106 - val_accuracy: 0.4872\n",
      "Epoch 155/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6143 - accuracy: 0.6115 - val_loss: 7.3214 - val_accuracy: 0.4862\n",
      "Epoch 156/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6161 - accuracy: 0.6132 - val_loss: 7.3878 - val_accuracy: 0.4850\n",
      "Epoch 157/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6097 - accuracy: 0.6152 - val_loss: 7.6643 - val_accuracy: 0.4870\n",
      "Epoch 158/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6114 - accuracy: 0.6138 - val_loss: 7.7371 - val_accuracy: 0.4859\n",
      "Epoch 159/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6100 - accuracy: 0.6164 - val_loss: 8.0126 - val_accuracy: 0.4794\n",
      "Epoch 160/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6185 - accuracy: 0.6116 - val_loss: 7.3133 - val_accuracy: 0.4914\n",
      "Epoch 161/300\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 0.6132 - accuracy: 0.6120 - val_loss: 7.3705 - val_accuracy: 0.4962\n",
      "Epoch 162/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6141 - accuracy: 0.6180 - val_loss: 7.8471 - val_accuracy: 0.5014\n",
      "Epoch 163/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6119 - accuracy: 0.6170 - val_loss: 7.8953 - val_accuracy: 0.4916\n",
      "Epoch 164/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6103 - accuracy: 0.6158 - val_loss: 8.7104 - val_accuracy: 0.4926\n",
      "Epoch 165/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6128 - accuracy: 0.6144 - val_loss: 7.0211 - val_accuracy: 0.4997\n",
      "Epoch 166/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6086 - accuracy: 0.6161 - val_loss: 7.7271 - val_accuracy: 0.4951\n",
      "Epoch 167/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6064 - accuracy: 0.6168 - val_loss: 7.9689 - val_accuracy: 0.4956\n",
      "Epoch 168/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6051 - accuracy: 0.6215 - val_loss: 7.8109 - val_accuracy: 0.4947\n",
      "Epoch 169/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6085 - accuracy: 0.6201 - val_loss: 8.6166 - val_accuracy: 0.4942\n",
      "Epoch 170/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6063 - accuracy: 0.6165 - val_loss: 8.9686 - val_accuracy: 0.4978\n",
      "Epoch 171/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6050 - accuracy: 0.6193 - val_loss: 8.6436 - val_accuracy: 0.4947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6105 - accuracy: 0.6163 - val_loss: 9.1564 - val_accuracy: 0.4954\n",
      "Epoch 173/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6061 - accuracy: 0.6199 - val_loss: 9.0541 - val_accuracy: 0.4944\n",
      "Epoch 174/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6043 - accuracy: 0.6201 - val_loss: 8.6648 - val_accuracy: 0.4979\n",
      "Epoch 175/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6034 - accuracy: 0.6208 - val_loss: 8.7967 - val_accuracy: 0.4983\n",
      "Epoch 176/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6019 - accuracy: 0.6232 - val_loss: 8.9974 - val_accuracy: 0.4979\n",
      "Epoch 177/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6047 - accuracy: 0.6212 - val_loss: 9.4815 - val_accuracy: 0.4960\n",
      "Epoch 178/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6059 - accuracy: 0.6185 - val_loss: 9.7068 - val_accuracy: 0.4924\n",
      "Epoch 179/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6037 - accuracy: 0.6226 - val_loss: 10.2590 - val_accuracy: 0.4945\n",
      "Epoch 180/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6114 - accuracy: 0.6145 - val_loss: 9.4712 - val_accuracy: 0.4997\n",
      "Epoch 181/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6027 - accuracy: 0.6254 - val_loss: 9.5379 - val_accuracy: 0.5028\n",
      "Epoch 182/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6059 - accuracy: 0.6157 - val_loss: 11.5981 - val_accuracy: 0.4994\n",
      "Epoch 183/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6064 - accuracy: 0.6182 - val_loss: 9.9261 - val_accuracy: 0.4989\n",
      "Epoch 184/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6050 - accuracy: 0.6210 - val_loss: 10.0398 - val_accuracy: 0.5025\n",
      "Epoch 185/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6008 - accuracy: 0.6209 - val_loss: 10.4519 - val_accuracy: 0.4994\n",
      "Epoch 186/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5998 - accuracy: 0.6244 - val_loss: 10.4814 - val_accuracy: 0.4940\n",
      "Epoch 187/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5985 - accuracy: 0.6216 - val_loss: 10.5222 - val_accuracy: 0.4982\n",
      "Epoch 188/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5979 - accuracy: 0.6264 - val_loss: 10.6552 - val_accuracy: 0.5003\n",
      "Epoch 189/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6029 - accuracy: 0.6252 - val_loss: 9.6554 - val_accuracy: 0.5048\n",
      "Epoch 190/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6101 - accuracy: 0.6195 - val_loss: 9.7915 - val_accuracy: 0.5023\n",
      "Epoch 191/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6089 - accuracy: 0.6197 - val_loss: 10.0620 - val_accuracy: 0.4982\n",
      "Epoch 192/300\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.5996 - accuracy: 0.6242 - val_loss: 9.9608 - val_accuracy: 0.4997\n",
      "Epoch 193/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5974 - accuracy: 0.6232 - val_loss: 10.0523 - val_accuracy: 0.5013\n",
      "Epoch 194/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5950 - accuracy: 0.6286 - val_loss: 10.1726 - val_accuracy: 0.4987\n",
      "Epoch 195/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5954 - accuracy: 0.6271 - val_loss: 10.3005 - val_accuracy: 0.4998\n",
      "Epoch 196/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5953 - accuracy: 0.6271 - val_loss: 10.5309 - val_accuracy: 0.4978\n",
      "Epoch 197/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5952 - accuracy: 0.6276 - val_loss: 10.9530 - val_accuracy: 0.5016\n",
      "Epoch 198/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5940 - accuracy: 0.6281 - val_loss: 10.8983 - val_accuracy: 0.4989\n",
      "Epoch 199/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5989 - accuracy: 0.6214 - val_loss: 10.4255 - val_accuracy: 0.5019\n",
      "Epoch 200/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.6000 - accuracy: 0.6221 - val_loss: 10.0581 - val_accuracy: 0.5005\n",
      "Epoch 201/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5989 - accuracy: 0.6232 - val_loss: 10.1965 - val_accuracy: 0.4960\n",
      "Epoch 202/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.6000 - accuracy: 0.6225 - val_loss: 10.0666 - val_accuracy: 0.5020\n",
      "Epoch 203/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5952 - accuracy: 0.6257 - val_loss: 10.3094 - val_accuracy: 0.4991\n",
      "Epoch 204/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5963 - accuracy: 0.6262 - val_loss: 11.5073 - val_accuracy: 0.4968\n",
      "Epoch 205/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5938 - accuracy: 0.6277 - val_loss: 11.9496 - val_accuracy: 0.4981\n",
      "Epoch 206/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5915 - accuracy: 0.6307 - val_loss: 11.1628 - val_accuracy: 0.4994\n",
      "Epoch 207/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5920 - accuracy: 0.6273 - val_loss: 11.8978 - val_accuracy: 0.4979\n",
      "Epoch 208/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5904 - accuracy: 0.6285 - val_loss: 12.4540 - val_accuracy: 0.5000\n",
      "Epoch 209/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5964 - accuracy: 0.6301 - val_loss: 12.0629 - val_accuracy: 0.4995\n",
      "Epoch 210/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5949 - accuracy: 0.6265 - val_loss: 11.5090 - val_accuracy: 0.5009\n",
      "Epoch 211/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5893 - accuracy: 0.6319 - val_loss: 11.2808 - val_accuracy: 0.4987\n",
      "Epoch 212/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5886 - accuracy: 0.6321 - val_loss: 11.4431 - val_accuracy: 0.4987\n",
      "Epoch 213/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5885 - accuracy: 0.6305 - val_loss: 11.4273 - val_accuracy: 0.4991\n",
      "Epoch 214/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5900 - accuracy: 0.6290 - val_loss: 11.5295 - val_accuracy: 0.4975\n",
      "Epoch 215/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5864 - accuracy: 0.6335 - val_loss: 12.0686 - val_accuracy: 0.4968\n",
      "Epoch 216/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5908 - accuracy: 0.6317 - val_loss: 12.2769 - val_accuracy: 0.4956\n",
      "Epoch 217/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5901 - accuracy: 0.6301 - val_loss: 13.3084 - val_accuracy: 0.5013\n",
      "Epoch 218/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5946 - accuracy: 0.6288 - val_loss: 13.3358 - val_accuracy: 0.5013\n",
      "Epoch 219/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5979 - accuracy: 0.6314 - val_loss: 14.9843 - val_accuracy: 0.4984\n",
      "Epoch 220/300\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.5948 - accuracy: 0.6279 - val_loss: 13.6302 - val_accuracy: 0.4992\n",
      "Epoch 221/300\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 0.5887 - accuracy: 0.6320 - val_loss: 13.9006 - val_accuracy: 0.4989\n",
      "Epoch 222/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5876 - accuracy: 0.6313 - val_loss: 14.6216 - val_accuracy: 0.5019\n",
      "Epoch 223/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5869 - accuracy: 0.6308 - val_loss: 14.3958 - val_accuracy: 0.5003\n",
      "Epoch 224/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5834 - accuracy: 0.6363 - val_loss: 14.6759 - val_accuracy: 0.5011\n",
      "Epoch 225/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5844 - accuracy: 0.6350 - val_loss: 14.1150 - val_accuracy: 0.5016\n",
      "Epoch 226/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5827 - accuracy: 0.6370 - val_loss: 14.3081 - val_accuracy: 0.5003\n",
      "Epoch 227/300\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 0.5875 - accuracy: 0.6314 - val_loss: 15.7474 - val_accuracy: 0.5010\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 7s 82ms/step - loss: 0.5909 - accuracy: 0.6317 - val_loss: 14.8445 - val_accuracy: 0.5050\n",
      "Epoch 229/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5852 - accuracy: 0.6348 - val_loss: 15.5144 - val_accuracy: 0.5015\n",
      "Epoch 230/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5810 - accuracy: 0.6397 - val_loss: 15.6018 - val_accuracy: 0.4989\n",
      "Epoch 231/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5844 - accuracy: 0.6354 - val_loss: 15.8893 - val_accuracy: 0.5009\n",
      "Epoch 232/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5867 - accuracy: 0.6320 - val_loss: 15.1932 - val_accuracy: 0.4992\n",
      "Epoch 233/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5915 - accuracy: 0.6310 - val_loss: 15.0326 - val_accuracy: 0.5008\n",
      "Epoch 234/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5880 - accuracy: 0.6309 - val_loss: 12.9823 - val_accuracy: 0.5026\n",
      "Epoch 235/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5835 - accuracy: 0.6325 - val_loss: 13.8564 - val_accuracy: 0.4967\n",
      "Epoch 236/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5815 - accuracy: 0.6354 - val_loss: 14.0147 - val_accuracy: 0.4988\n",
      "Epoch 237/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5808 - accuracy: 0.6378 - val_loss: 14.3250 - val_accuracy: 0.5023\n",
      "Epoch 238/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5817 - accuracy: 0.6386 - val_loss: 15.1134 - val_accuracy: 0.5051\n",
      "Epoch 239/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5826 - accuracy: 0.6376 - val_loss: 15.0648 - val_accuracy: 0.5046\n",
      "Epoch 240/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5811 - accuracy: 0.6392 - val_loss: 16.2796 - val_accuracy: 0.5037\n",
      "Epoch 241/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5826 - accuracy: 0.6375 - val_loss: 15.7467 - val_accuracy: 0.5041\n",
      "Epoch 242/300\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.5785 - accuracy: 0.6383 - val_loss: 15.5347 - val_accuracy: 0.5026\n",
      "Epoch 243/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5782 - accuracy: 0.6385 - val_loss: 16.4949 - val_accuracy: 0.5005\n",
      "Epoch 244/300\n",
      "80/80 [==============================] - 6s 78ms/step - loss: 0.5793 - accuracy: 0.6397 - val_loss: 15.7049 - val_accuracy: 0.5022\n",
      "Epoch 245/300\n",
      "80/80 [==============================] - 5s 62ms/step - loss: 0.5860 - accuracy: 0.6352 - val_loss: 13.0185 - val_accuracy: 0.5009\n",
      "Epoch 246/300\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.5909 - accuracy: 0.6325 - val_loss: 13.5355 - val_accuracy: 0.5067\n",
      "Epoch 247/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5856 - accuracy: 0.6368 - val_loss: 12.5446 - val_accuracy: 0.5044\n",
      "Epoch 248/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5819 - accuracy: 0.6385 - val_loss: 13.7108 - val_accuracy: 0.5058\n",
      "Epoch 249/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5774 - accuracy: 0.6431 - val_loss: 13.8057 - val_accuracy: 0.5050\n",
      "Epoch 250/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5753 - accuracy: 0.6421 - val_loss: 13.8105 - val_accuracy: 0.5046\n",
      "Epoch 251/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5735 - accuracy: 0.6413 - val_loss: 14.0312 - val_accuracy: 0.5034\n",
      "Epoch 252/300\n",
      "80/80 [==============================] - 4s 50ms/step - loss: 0.5737 - accuracy: 0.6446 - val_loss: 14.4408 - val_accuracy: 0.5019\n",
      "Epoch 253/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5851 - accuracy: 0.6354 - val_loss: 14.4055 - val_accuracy: 0.5037\n",
      "Epoch 254/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5812 - accuracy: 0.6381 - val_loss: 14.3676 - val_accuracy: 0.5043\n",
      "Epoch 255/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5763 - accuracy: 0.6397 - val_loss: 14.5413 - val_accuracy: 0.5043\n",
      "Epoch 256/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5730 - accuracy: 0.6427 - val_loss: 14.5290 - val_accuracy: 0.5055\n",
      "Epoch 257/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5755 - accuracy: 0.6440 - val_loss: 14.8701 - val_accuracy: 0.5063\n",
      "Epoch 258/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5734 - accuracy: 0.6431 - val_loss: 14.6475 - val_accuracy: 0.5045\n",
      "Epoch 259/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5710 - accuracy: 0.6461 - val_loss: 15.3048 - val_accuracy: 0.5045\n",
      "Epoch 260/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5703 - accuracy: 0.6464 - val_loss: 15.2845 - val_accuracy: 0.5050\n",
      "Epoch 261/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5693 - accuracy: 0.6482 - val_loss: 15.4378 - val_accuracy: 0.5046\n",
      "Epoch 262/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5687 - accuracy: 0.6447 - val_loss: 15.2648 - val_accuracy: 0.5046\n",
      "Epoch 263/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5717 - accuracy: 0.6481 - val_loss: 15.5418 - val_accuracy: 0.5047\n",
      "Epoch 264/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5770 - accuracy: 0.6435 - val_loss: 14.9606 - val_accuracy: 0.5050\n",
      "Epoch 265/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5761 - accuracy: 0.6421 - val_loss: 15.3117 - val_accuracy: 0.5048\n",
      "Epoch 266/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5718 - accuracy: 0.6443 - val_loss: 15.9137 - val_accuracy: 0.5035\n",
      "Epoch 267/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5718 - accuracy: 0.6458 - val_loss: 15.4268 - val_accuracy: 0.5015\n",
      "Epoch 268/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5747 - accuracy: 0.6443 - val_loss: 15.7848 - val_accuracy: 0.5051\n",
      "Epoch 269/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5689 - accuracy: 0.6467 - val_loss: 15.5418 - val_accuracy: 0.5017\n",
      "Epoch 270/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5708 - accuracy: 0.6458 - val_loss: 16.8767 - val_accuracy: 0.5026\n",
      "Epoch 271/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5776 - accuracy: 0.6418 - val_loss: 16.6669 - val_accuracy: 0.5067\n",
      "Epoch 272/300\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.5699 - accuracy: 0.6456 - val_loss: 17.5452 - val_accuracy: 0.5052\n",
      "Epoch 273/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5714 - accuracy: 0.6464 - val_loss: 17.1405 - val_accuracy: 0.5012\n",
      "Epoch 274/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5707 - accuracy: 0.6447 - val_loss: 16.2700 - val_accuracy: 0.5031\n",
      "Epoch 275/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5635 - accuracy: 0.6516 - val_loss: 15.6545 - val_accuracy: 0.5027\n",
      "Epoch 276/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5637 - accuracy: 0.6517 - val_loss: 16.5031 - val_accuracy: 0.5030\n",
      "Epoch 277/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5644 - accuracy: 0.6488 - val_loss: 15.2996 - val_accuracy: 0.5034\n",
      "Epoch 278/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5720 - accuracy: 0.6448 - val_loss: 15.5304 - val_accuracy: 0.5026\n",
      "Epoch 279/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5781 - accuracy: 0.6451 - val_loss: 15.4695 - val_accuracy: 0.5043\n",
      "Epoch 280/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5740 - accuracy: 0.6474 - val_loss: 15.2575 - val_accuracy: 0.5039\n",
      "Epoch 281/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5669 - accuracy: 0.6483 - val_loss: 14.6383 - val_accuracy: 0.5066\n",
      "Epoch 282/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5638 - accuracy: 0.6493 - val_loss: 15.8469 - val_accuracy: 0.5065\n",
      "Epoch 283/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5652 - accuracy: 0.6495 - val_loss: 16.2962 - val_accuracy: 0.5083\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5635 - accuracy: 0.6504 - val_loss: 16.3008 - val_accuracy: 0.5064\n",
      "Epoch 285/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5652 - accuracy: 0.6526 - val_loss: 15.6851 - val_accuracy: 0.5047\n",
      "Epoch 286/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5671 - accuracy: 0.6497 - val_loss: 16.0965 - val_accuracy: 0.5046\n",
      "Epoch 287/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5634 - accuracy: 0.6500 - val_loss: 16.2953 - val_accuracy: 0.5054\n",
      "Epoch 288/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5627 - accuracy: 0.6523 - val_loss: 16.8704 - val_accuracy: 0.5054\n",
      "Epoch 289/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5592 - accuracy: 0.6550 - val_loss: 15.9773 - val_accuracy: 0.5048\n",
      "Epoch 290/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5659 - accuracy: 0.6493 - val_loss: 16.3268 - val_accuracy: 0.5056\n",
      "Epoch 291/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5592 - accuracy: 0.6547 - val_loss: 16.4200 - val_accuracy: 0.5056\n",
      "Epoch 292/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5616 - accuracy: 0.6542 - val_loss: 15.2204 - val_accuracy: 0.5059\n",
      "Epoch 293/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5588 - accuracy: 0.6530 - val_loss: 16.5192 - val_accuracy: 0.5058\n",
      "Epoch 294/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5593 - accuracy: 0.6505 - val_loss: 17.1764 - val_accuracy: 0.5045\n",
      "Epoch 295/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5673 - accuracy: 0.6498 - val_loss: 17.2038 - val_accuracy: 0.5045\n",
      "Epoch 296/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5605 - accuracy: 0.6515 - val_loss: 17.2839 - val_accuracy: 0.5055\n",
      "Epoch 297/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5592 - accuracy: 0.6526 - val_loss: 16.7185 - val_accuracy: 0.5048\n",
      "Epoch 298/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5646 - accuracy: 0.6497 - val_loss: 16.3296 - val_accuracy: 0.5057\n",
      "Epoch 299/300\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.5634 - accuracy: 0.6519 - val_loss: 17.0489 - val_accuracy: 0.5068\n",
      "Epoch 300/300\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.5592 - accuracy: 0.6562 - val_loss: 17.3135 - val_accuracy: 0.5059\n"
     ]
    }
   ],
   "source": [
    "# model1.compile(optimizer=opt, \n",
    "#               loss = 'binary_crossentropy',\n",
    "#               metrics=[m])\n",
    "# history = model1.fit( [X_dynamic_train_reshaped[:,-40:,:],X_static_train], y_train, epochs=500, batch_size= 500, validation_data=( [X_dynamic_test_reshaped[:,-40:,:],X_static_test], y_test)  )\n",
    "\n",
    "model1.compile(optimizer='adam', \n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model1.fit( X_dynamic_train_reshaped[:,-36:,:], y_train, epochs=300, batch_size= 420, validation_data= (X_dynamic_test_reshaped[:,-36:,:], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "front-world",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00210181, 0.00325116, 0.00205564, 0.00144565, 0.00137958,\n",
       "       0.00140342, 0.00069939, 0.00134703, 0.00125825, 0.00117195,\n",
       "       0.00166388, 0.00045813])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dynamic_train_reshaped[:,-12:,:].mean(axis=0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adjusted-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR\n",
       "100002    1\n",
       "100010    0\n",
       "100017    0\n",
       "100021    0\n",
       "100030    0\n",
       "         ..\n",
       "337787    1\n",
       "337794    1\n",
       "337816    1\n",
       "337820    1\n",
       "337825    0\n",
       "Name: TARGET, Length: 33265, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "about-management",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'auc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6c1893d4d37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'auc'"
     ]
    }
   ],
   "source": [
    "loss_train = history.history['auc']\n",
    "loss_val = history.history['val_auc']\n",
    "epochs = range(300)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training acc')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation acc')\n",
    "plt.title('Training and Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_train = history.history['auc']\n",
    "loss_val = history.history['val_auc']\n",
    "epochs = range(500)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training acc')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation acc')\n",
    "plt.title('Training and Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = history.history['auc_9']\n",
    "loss_val = history.history['val_auc_9']\n",
    "epochs = range(300)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training acc')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation acc')\n",
    "plt.title('Training and Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_train = history.history['auc']\n",
    "loss_val = history.history['val_auc']\n",
    "epochs = range(500)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training acc')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation acc')\n",
    "plt.title('Training and Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred = model1.predict([X_dynamic_test, X_static_test]).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "# plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thresholds_keras)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
